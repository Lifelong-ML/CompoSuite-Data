{
    "ac_kwargs":	{
        "hidden_sizes":	[
            64,
            64
        ],
        "log_std_init":	0.0
    },
    "actor_critic":	"MLPActorCritic",
    "checkpoint":	{
        "epoch":	359,
        "model":	{
            "pi.mu_net.0.bias":	"tensor([ 0.0253,  0.1218,  0.0421, -0.0865, -0.0423, -0.0277,  0.0464, -0.0324,\n        -0.0037, -0.0316, -0.0358,  0.0239, -0.0748, -0.0770,  0.1108,  0.1084,\n        -0.0027,  0.0929,  0.0933, -0.0721, -0.0409, -0.0899,  0.0487,  0.0035,\n        -0.0225,  0.1037, -0.0344, -0.0661, -0.0681, -0.0804,  0.0987, -0.0607,\n        -0.0177,  0.0677, -0.0878, -0.0606,  0.1042, -0.0553, -0.0704, -0.0302,\n         0.0110,  0.0198,  0.0541, -0.0900,  0.0906, -0.1041,  0.0684, -0.0426,\n        -0.0311,  0.1007, -0.1168, -0.0176,  0.0850,  0.0991, -0.1196,  0.0306,\n         0.1038, -0.1155,  0.0167, -0.0548,  0.0186, -0.0764,  0.0395, -0.0477])",
            "pi.mu_net.0.weight":	"tensor([[ 0.0223,  0.2005, -0.1155,  ...,  0.1623,  0.1328, -0.0369],\n        [-0.0578, -0.0642, -0.0384,  ...,  0.4583, -0.1800,  0.2776],\n        [-0.0464, -0.0496,  0.0969,  ..., -0.5032, -0.1793,  0.1512],\n        ...,\n        [ 0.0580, -0.0968, -0.0686,  ...,  0.7236,  0.2798,  0.3170],\n        [-0.0804, -0.0437,  0.0259,  ..., -0.0269, -0.0821, -0.0832],\n        [ 0.0903, -0.0660,  0.0495,  ...,  0.0759,  0.0847, -0.0446]])",
            "pi.mu_net.2.bias":	"tensor([-0.0704,  0.0469,  0.1490,  0.0372,  0.0760, -0.1213,  0.0042,  0.0137,\n        -0.0364,  0.0228,  0.0270, -0.0875,  0.0170,  0.0666,  0.1153, -0.0489,\n         0.1031, -0.0261,  0.0279, -0.1024, -0.1007, -0.0566,  0.0444,  0.0924,\n         0.0646, -0.0118,  0.0624, -0.0982,  0.0989, -0.0782, -0.1432,  0.0507,\n        -0.0966, -0.0998, -0.0926, -0.0605,  0.0410,  0.0129, -0.0807,  0.0185,\n        -0.0845, -0.0729, -0.0680,  0.0085,  0.0461,  0.0581,  0.0239,  0.0685,\n        -0.0376, -0.0012,  0.1263, -0.0300,  0.0676, -0.0796,  0.0894,  0.1140,\n         0.0941, -0.0353, -0.0541,  0.0126, -0.0432,  0.1040, -0.0139, -0.0404])",
            "pi.mu_net.2.weight":	"tensor([[ 0.3256, -0.0964, -0.2819,  ...,  0.0994, -0.0061,  0.1198],\n        [-0.2832, -0.0007,  0.3711,  ..., -0.1398,  0.0411,  0.0498],\n        [-0.1573, -0.3903, -0.1932,  ...,  0.4610,  0.1051,  0.3533],\n        ...,\n        [ 0.5405, -0.0265, -0.1761,  ...,  0.0680, -0.0809,  0.0157],\n        [ 0.1083, -0.0409,  0.3432,  ..., -0.0106,  0.2630, -0.0499],\n        [ 0.1968,  0.3533,  0.1768,  ..., -0.3318,  0.1253, -0.2632]])",
            "pi.mu_net.4.bias":	"tensor([-0.0116,  0.1541,  0.0806,  0.0759,  0.1909, -0.0286, -0.1436, -0.1330])",
            "pi.mu_net.4.weight":	"tensor([[ 5.3086e-01, -5.2832e-01, -3.8533e-01,  3.2926e-01,  1.7432e-01,\n         -2.2616e-01,  1.7031e-02,  4.9495e-01, -6.2467e-02, -1.5896e-01,\n          4.9127e-02, -1.9507e-01, -2.8108e-01, -4.1938e-01, -5.1758e-02,\n         -1.3181e-01, -7.8719e-01, -1.0272e-01, -1.6375e-01,  4.1974e-01,\n         -5.1021e-02, -6.0497e-01, -2.9587e-01,  7.0415e-01,  3.5798e-01,\n          8.1473e-01,  3.0305e-01,  4.0416e-01, -2.3128e-01,  2.3231e-03,\n          2.0695e-01,  6.3831e-01, -1.5162e-01, -3.1258e-02, -5.7688e-01,\n          5.6247e-01, -6.8718e-01, -9.1635e-02,  1.7018e-01,  6.8298e-02,\n          1.4776e-01, -3.2893e-01,  2.5850e-01, -4.6997e-01,  4.2470e-01,\n         -7.3858e-01,  1.9420e-01,  9.8235e-01, -4.7830e-01, -2.1431e-01,\n         -6.8058e-02,  1.8715e-01,  8.5113e-02,  7.0769e-01, -2.5103e-02,\n          1.1018e-01, -7.0688e-01, -5.6957e-01, -4.1794e-01, -9.6613e-02,\n          8.4100e-02,  5.7626e-01,  3.2898e-01, -4.1536e-02],\n        [-2.5917e-01,  2.6483e-01, -6.4645e-02, -1.0384e-01,  4.2658e-03,\n         -4.9231e-01,  1.5426e-01,  1.6503e-01,  1.0728e-01, -3.6076e-02,\n         -8.5280e-01, -1.1002e-01, -9.0797e-01,  6.3156e-01,  3.6705e-01,\n         -3.2809e-01, -2.9577e-01, -2.5839e-01,  5.8025e-01,  1.4698e-01,\n         -2.2453e-01,  2.6025e-03,  5.1632e-01, -1.8662e-01, -8.3170e-01,\n         -6.1186e-02,  5.0859e-01,  6.2856e-01,  5.1950e-02,  2.8290e-01,\n         -5.3749e-01,  1.5289e-01, -2.9481e-01, -6.7729e-01,  5.3418e-01,\n          3.9454e-01, -3.4867e-01, -5.3361e-01,  6.8476e-01,  5.5195e-01,\n         -5.6110e-01,  4.0891e-01,  1.6403e-02,  3.7952e-01,  2.1661e-01,\n          7.8062e-02, -5.7464e-02, -1.4409e-01, -2.7106e-01,  3.0851e-01,\n         -4.7825e-02,  1.0380e-01,  1.0001e-01, -5.5589e-01,  1.2350e-01,\n          6.9663e-01,  4.3038e-01,  8.1210e-01,  4.6722e-01, -4.3310e-02,\n          5.9564e-01, -3.5291e-01,  2.2155e-01,  7.3264e-01],\n        [-1.5952e-01, -2.1557e-01,  8.0873e-01,  2.3353e-02, -6.7325e-01,\n         -3.1773e-01, -4.7256e-01,  9.0273e-02,  5.3924e-01, -4.4433e-01,\n         -4.2593e-01, -6.4743e-01, -1.4019e-01, -2.1657e-01, -7.6285e-02,\n          2.1056e-01, -1.1168e-01, -3.1750e-01, -4.7466e-01,  3.9788e-01,\n         -8.3216e-01, -2.6073e-01, -2.1068e-01,  6.6231e-01,  2.9450e-01,\n          6.4567e-01,  2.2839e-01, -2.8438e-01,  4.3725e-02, -6.0342e-01,\n         -2.4658e-02,  6.0109e-01,  1.4236e-01,  5.5670e-01, -7.0769e-01,\n          6.6993e-01,  6.6784e-03, -2.9229e-01, -3.4084e-01, -4.2969e-01,\n          8.2806e-01,  4.1425e-01, -3.2646e-01, -2.2138e-01,  3.3197e-01,\n         -3.8088e-01, -7.9880e-01, -1.3332e-01,  6.2359e-04, -9.1248e-01,\n         -5.4267e-01,  5.0524e-01,  6.7996e-01, -3.2317e-01,  6.8259e-01,\n          9.4830e-02,  2.7982e-01, -3.4773e-01, -9.4129e-02,  3.7365e-01,\n         -2.7455e-01,  2.0330e-01,  1.5899e-01, -2.9908e-01],\n        [ 5.3632e-01, -2.8939e-01,  4.7079e-01,  1.4062e-01,  4.9197e-01,\n         -3.8238e-01, -3.9480e-01, -4.1475e-01,  3.0383e-01,  1.2049e-01,\n          3.7440e-01, -3.7741e-01,  5.1423e-01, -7.3560e-01, -2.0411e-01,\n          7.8425e-01,  5.6854e-01, -6.8654e-01,  8.7900e-02,  3.0989e-01,\n          2.0847e-01,  1.4459e-01, -2.8488e-01, -3.3578e-01, -1.3363e-01,\n          4.2557e-02, -6.4555e-01,  3.0846e-01,  7.1155e-01, -1.3326e-02,\n         -8.3420e-03,  8.7430e-02, -1.7976e-01,  1.5893e-01, -8.3469e-01,\n         -1.0374e-02,  2.0325e-01, -3.9237e-01, -2.1206e-01, -4.7152e-01,\n          5.5027e-01, -9.9519e-02, -7.9608e-01, -6.2755e-01, -2.1162e-01,\n         -1.1419e-01,  7.0958e-02, -1.5992e-01,  2.2237e-01, -7.8219e-02,\n          5.0239e-01,  1.9377e-01,  2.1490e-01, -2.1251e-01,  5.6663e-01,\n          1.3397e-01,  1.0128e-01,  1.1249e-02,  3.5982e-01,  5.0968e-01,\n         -1.7612e-01,  2.6400e-01, -7.3314e-01, -8.5657e-02],\n        [ 6.5437e-01,  2.5699e-01,  1.0700e-01,  3.6244e-01, -1.7795e-01,\n         -2.5893e-01, -5.3501e-01, -2.9280e-01,  7.2281e-01,  1.7963e-01,\n         -2.2071e-01, -4.0546e-01,  1.5198e-01,  6.2088e-02,  4.5992e-01,\n          2.9463e-01, -2.7411e-02,  1.2245e-01, -3.7749e-01, -1.3597e-01,\n         -2.2835e-01, -3.3486e-01,  3.9627e-01,  1.4824e-01,  4.5684e-01,\n          6.8787e-01, -6.4861e-01, -2.6419e-01,  1.1865e-01, -1.8419e-01,\n          3.4751e-01, -1.2558e-01,  2.1679e-01,  2.0117e-01, -4.6794e-01,\n          3.8630e-01, -3.8380e-01, -6.7773e-02, -4.9919e-01, -1.4938e-01,\n          2.2262e-01,  2.6254e-01, -3.2971e-01,  5.2024e-02, -5.2916e-01,\n         -1.0778e-01, -3.6219e-02,  6.2259e-03, -4.6357e-01, -5.4295e-01,\n          1.1663e-01, -1.4003e-01, -3.0262e-01, -2.8421e-02, -1.4199e-01,\n          1.8550e-02, -5.8663e-01, -2.8345e-01, -1.1215e-01,  5.9908e-01,\n         -6.5200e-01,  4.2433e-01,  1.4760e-01, -3.8608e-01],\n        [ 1.4469e-01,  3.4085e-01, -1.0004e-01, -1.5622e-01, -3.2828e-01,\n          1.9433e-01, -2.8099e-01, -5.0020e-01, -5.4173e-01, -5.0856e-01,\n          4.2243e-01,  2.4891e-01, -1.1971e-01, -6.9958e-01, -2.3447e-01,\n         -5.4121e-03,  5.8901e-01, -4.8846e-02, -1.1418e-01, -8.5738e-01,\n         -3.4835e-01,  6.8224e-01,  3.7624e-01,  2.3614e-01, -1.6050e-01,\n          3.9478e-02,  5.3978e-01,  1.0710e-01,  7.8639e-02,  3.2226e-01,\n          2.9584e-01,  4.7717e-02,  1.3266e-02,  1.0182e-01,  1.5935e-02,\n          3.1884e-01,  1.9363e-01,  8.6005e-02, -2.5160e-01,  4.6599e-01,\n         -1.5911e-01,  1.2873e-01,  3.5541e-01,  4.5077e-02,  1.1778e-01,\n         -2.8187e-01, -4.9569e-01, -9.6089e-02, -2.0949e-01, -1.4647e-02,\n         -6.4763e-01,  5.2002e-01,  1.1344e-02, -3.3396e-01, -2.6665e-01,\n          1.2361e-02,  5.4572e-01, -9.1447e-02,  2.1233e-01,  4.0745e-01,\n          4.1084e-01,  3.0485e-01,  6.0379e-01, -1.9462e-01],\n        [-1.3928e-01, -1.7313e-01, -2.8594e-01, -5.4221e-01, -2.8777e-01,\n         -2.0848e-02, -4.8065e-01, -7.9602e-02, -3.0806e-01,  4.3987e-01,\n         -3.7459e-02, -1.9415e-01,  2.7678e-01, -1.4413e-01, -1.4817e-01,\n          2.6020e-01, -5.8236e-01,  6.0967e-01,  1.1808e-01, -7.5409e-02,\n          8.0029e-02, -1.5321e-01,  6.9792e-02,  1.1144e-01, -1.6879e-02,\n          5.1120e-02,  1.9720e-01, -3.2507e-01, -9.3931e-02,  4.3082e-01,\n          2.9327e-03, -1.9732e-01, -9.6577e-02, -3.3148e-01, -3.1165e-03,\n          4.8034e-02, -3.5448e-03, -4.1893e-01, -3.4100e-01,  1.4704e-01,\n         -1.8676e-01, -2.0042e-02,  4.0182e-01, -3.0167e-01, -6.1028e-01,\n          2.3178e-01,  3.3400e-01, -6.9161e-02,  3.1164e-01,  5.4247e-02,\n          2.8802e-01, -2.3609e-02, -3.5991e-01,  7.3580e-02, -3.4443e-01,\n         -2.1651e-01,  1.4284e-01,  1.0265e-01, -1.2190e-01,  2.4163e-01,\n         -3.2103e-01, -7.2099e-02,  2.0358e-01,  2.2930e-01],\n        [ 4.1422e-01, -1.2699e-02, -6.6205e-02,  3.0905e-01, -3.5316e-01,\n          9.9305e-02,  5.8360e-02, -3.5030e-01, -2.5496e-01, -4.5288e-01,\n          1.2698e-01, -2.8118e-01,  2.0336e-02, -2.6621e-01,  6.2473e-02,\n         -3.1096e-01,  3.8678e-01, -2.1329e-01, -5.3345e-01,  3.1587e-01,\n         -3.2546e-01,  5.9615e-01, -2.7272e-01,  1.4204e-01, -9.0964e-02,\n         -4.1311e-01, -8.0969e-02,  1.3563e-03,  1.4576e-01, -4.6308e-01,\n          4.4524e-01,  5.1337e-01,  5.0947e-01,  6.9750e-01,  1.4984e-02,\n         -8.2844e-02,  4.7653e-01, -3.9171e-02, -5.3065e-01, -4.1317e-01,\n          8.2595e-02, -4.5183e-01,  2.0538e-01, -4.7069e-01, -1.0474e-01,\n          4.5881e-01,  8.8202e-02,  1.7704e-01,  5.6327e-01, -8.6544e-01,\n          1.6326e-01, -2.8834e-01,  4.8514e-01, -5.6043e-02, -1.9389e-01,\n         -1.2785e-01, -7.8680e-02, -1.0825e-01,  1.2053e-01,  2.4147e-01,\n          3.3586e-01,  3.0611e-01, -1.6403e-01,  3.5602e-02]])",
            "v.v_net.0.bias":	"tensor([-0.1653,  0.1251,  0.1062, -0.1025, -0.0091,  0.1195,  0.0398, -0.0940,\n         0.0163, -0.1613,  0.0586, -0.0060,  0.0911, -0.0144, -0.0294,  0.1404,\n        -0.0519, -0.0664, -0.0644, -0.0771,  0.1030,  0.0737, -0.0492, -0.0113,\n        -0.0337, -0.0981,  0.1488, -0.1183,  0.0107,  0.0267,  0.0502, -0.0383,\n        -0.0546, -0.0576, -0.0336,  0.1098, -0.0693, -0.0336, -0.0279, -0.0303,\n         0.0157,  0.0285, -0.1333, -0.0663,  0.1391, -0.0391,  0.0498,  0.1174,\n         0.1293,  0.0291,  0.0189, -0.0585, -0.1154, -0.0870, -0.1042,  0.0878,\n        -0.0412, -0.0709, -0.0708, -0.0368,  0.0153, -0.0404, -0.0161, -0.0044])",
            "v.v_net.0.weight":	"tensor([[ 0.1710,  0.0530, -0.0808,  ..., -0.4896, -0.0513, -0.2015],\n        [ 0.1242, -0.6192, -0.1192,  ..., -0.0428,  0.2291, -0.2182],\n        [-0.0764,  0.1499,  0.0601,  ..., -0.7319,  0.2674, -0.1124],\n        ...,\n        [-0.0622, -0.0186, -0.0817,  ..., -0.5355, -0.0854,  0.0556],\n        [-0.0588,  0.1541, -0.0123,  ..., -0.2843, -0.7974,  0.5104],\n        [ 0.1215,  0.4658, -0.0822,  ...,  0.1928, -0.1702,  0.4053]])",
            "v.v_net.2.bias":	"tensor([-0.2549, -0.1682, -0.1536,  0.1895,  0.0849,  0.0223,  0.0537,  0.1208,\n        -0.0668,  0.2126,  0.0885,  0.1030,  0.1105, -0.0587,  0.0088,  0.1716,\n         0.1531,  0.0977,  0.1204,  0.0890, -0.0497, -0.1098, -0.1064,  0.0171,\n        -0.1001,  0.1143,  0.0221, -0.0540,  0.0289, -0.0249,  0.1090, -0.1646,\n        -0.1837, -0.1114, -0.0502, -0.0755,  0.0832, -0.1291, -0.0877,  0.2799,\n         0.0670,  0.0167,  0.0731, -0.0372,  0.0011,  0.0652, -0.0524,  0.1249,\n         0.1460, -0.1026, -0.1767, -0.1171, -0.0480, -0.0870, -0.0807,  0.0033,\n         0.0277, -0.0135, -0.0225,  0.1064,  0.0461, -0.0291, -0.0550,  0.0534])",
            "v.v_net.2.weight":	"tensor([[ 0.7934,  0.2360,  0.1069,  ...,  0.0904,  0.7431,  0.5355],\n        [ 0.8921, -0.0160, -0.0762,  ...,  0.6910,  0.0182, -0.4550],\n        [-0.4660, -0.3452, -0.1092,  ..., -0.5514, -0.0330,  1.2056],\n        ...,\n        [ 0.3996,  0.5285, -0.1995,  ..., -0.3597,  0.1203,  0.1083],\n        [ 0.8536,  0.1342, -0.1863,  ...,  0.4889,  0.2249, -0.9985],\n        [-0.3735, -0.4782,  0.1555,  ...,  0.0926, -0.0951, -0.2540]])",
            "v.v_net.4.bias":	"tensor([1.0633])",
            "v.v_net.4.weight":	"tensor([[ 1.3748,  1.0991, -1.2823,  1.4097,  1.4597, -1.4330, -1.3916, -1.4911,\n          1.1842, -1.5150, -1.4321, -1.4554,  1.3795,  1.3278, -1.4852, -1.4626,\n         -1.3898,  1.3923,  1.4108,  1.3520,  1.2520, -1.5389, -1.3350,  1.3415,\n         -1.2869, -1.1454,  1.4019,  1.2234, -1.3887, -1.1587, -1.1726, -1.3996,\n         -1.3288, -1.3233,  1.4609, -1.3895, -1.2654, -1.3507,  1.4710, -1.3657,\n         -1.6159,  1.3168,  1.3492,  1.4781,  1.4158, -1.3605,  1.3540,  1.4049,\n          1.4060, -1.2485,  1.2217, -1.3204,  1.4285,  1.2257,  1.3769,  1.3459,\n          1.3083,  1.4133, -1.4156,  1.3532,  1.3904, -1.3431,  1.2868,  1.3975]])"
        },
        "pi_optimizer":	{
            "param_groups":	[
                {
                    "amsgrad":	false,
                    "betas":	[
                        0.9,
                        0.999
                    ],
                    "eps":	1e-08,
                    "lr":	0.0001,
                    "params":	[
                        139862174599568,
                        139862174598704,
                        139862174597264,
                        139862174597696,
                        139862174597192,
                        139862174599712
                    ],
                    "weight_decay":	0
                }
            ],
            "state":	{
                "139862174597192":	{
                    "exp_avg":	"tensor([[-3.0488e-05, -1.3503e-04,  7.3989e-06, -8.6633e-05,  7.1598e-05,\n          1.6856e-04,  1.2347e-04, -1.2897e-04, -1.3571e-04,  2.1995e-04,\n          1.4239e-04,  1.0287e-04,  1.8439e-04, -1.0416e-04, -1.0626e-04,\n         -1.6602e-04, -8.1290e-05,  9.5820e-05, -2.4445e-05,  1.5223e-04,\n          3.5605e-04,  2.4447e-05, -1.3348e-04, -3.8491e-04,  9.1471e-06,\n         -2.2068e-04, -2.7896e-05, -7.7190e-05, -2.6410e-04, -1.4056e-04,\n         -2.9634e-05, -5.2897e-05,  1.5082e-04,  5.4645e-05,  5.7126e-05,\n         -3.7425e-04,  1.9773e-04,  9.4687e-05, -7.4599e-05, -1.9849e-04,\n         -4.9928e-05, -1.1814e-04,  1.0810e-04, -8.2205e-05, -9.8086e-06,\n          3.7761e-04,  2.6207e-04,  7.2042e-05,  3.0334e-04, -1.3553e-04,\n          2.2403e-04, -2.2654e-04, -5.4230e-05,  1.2451e-04, -9.8581e-05,\n         -1.5948e-04, -6.6767e-05,  9.4261e-05, -1.7762e-04, -1.0281e-05,\n          1.3704e-05, -1.1880e-04, -3.9290e-04,  1.3509e-04],\n        [ 1.2998e-04, -2.1300e-04, -1.1275e-05,  7.2750e-06, -1.6390e-04,\n          2.8590e-06, -5.5393e-05, -2.1096e-05,  6.2467e-06, -1.7853e-04,\n         -4.7371e-05, -1.8787e-04,  1.5548e-04, -1.2234e-04, -6.6500e-05,\n         -4.1647e-05, -1.6267e-04,  2.0776e-05, -5.8622e-05,  2.2724e-04,\n         -6.8010e-05, -1.1352e-04, -2.2000e-04,  3.6414e-05,  2.2100e-04,\n          5.6876e-05,  2.3410e-05, -1.6836e-04, -1.0431e-04, -7.8972e-05,\n          1.1332e-04,  1.9512e-04,  7.6418e-05,  9.4469e-05, -1.5261e-04,\n         -5.3624e-05,  3.5026e-05, -7.0436e-05, -1.5248e-04, -1.9411e-04,\n          1.2625e-04, -1.9533e-04,  1.5160e-04, -2.4732e-04, -8.8498e-05,\n          1.3519e-04,  4.2269e-05,  2.4285e-04,  1.7641e-04, -1.7002e-04,\n          5.8710e-05, -1.4442e-04,  1.3716e-04,  1.5483e-04, -4.8085e-05,\n         -1.7915e-04, -1.7136e-04, -1.6651e-04, -2.7760e-04,  4.0240e-05,\n         -6.2247e-05, -1.2151e-04, -1.1268e-05,  3.0325e-05],\n        [-6.2205e-05,  5.2647e-05, -1.1850e-04, -1.3259e-04, -1.8676e-04,\n         -7.8259e-05, -5.8240e-05,  5.0431e-05,  1.2209e-04,  8.5498e-05,\n         -2.6005e-04, -1.4818e-04, -2.2442e-04,  1.2896e-04,  1.7951e-04,\n          2.2532e-05, -1.1400e-04,  2.1822e-04,  1.5893e-04,  3.0666e-05,\n         -1.4628e-04, -8.0502e-05,  1.2092e-04,  5.1324e-05, -5.8298e-05,\n          8.1589e-05, -9.7375e-06, -7.9541e-05, -1.8774e-04,  1.9623e-05,\n         -1.3172e-04, -3.3018e-05, -9.5844e-05, -1.8751e-04,  9.3889e-06,\n          1.5415e-04, -8.6045e-05, -9.7830e-05,  2.0923e-04,  1.1794e-04,\n         -4.6983e-05,  1.6525e-04,  5.5589e-05,  9.0991e-05, -1.5345e-04,\n         -3.6376e-05, -7.0438e-05, -2.3207e-05, -2.0031e-04,  7.3940e-05,\n         -1.0986e-05, -1.4810e-05, -7.8997e-05, -3.4974e-05, -1.8335e-05,\n          1.3990e-04, -8.2838e-06,  7.4420e-05, -7.0830e-05, -1.1675e-04,\n         -1.6480e-04, -2.9647e-05,  1.1597e-04,  1.0915e-04],\n        [-1.2592e-05, -1.6277e-05,  1.2299e-05,  6.8002e-05, -1.9181e-04,\n          5.5419e-05, -1.3158e-04, -2.1261e-04,  7.0046e-05, -1.9626e-04,\n         -8.3054e-05, -1.0202e-04,  2.7814e-04, -1.8281e-04,  4.1368e-05,\n         -5.4093e-05,  5.4034e-05,  7.0627e-05, -2.8274e-04, -4.4048e-05,\n         -2.4130e-04,  4.8416e-05, -8.6698e-05,  4.4220e-04,  2.3297e-04,\n          2.0924e-05,  8.5540e-05, -2.3672e-04, -2.5503e-05, -1.7554e-04,\n          1.1567e-04,  6.9594e-06,  2.3787e-04,  2.7714e-04, -2.8892e-05,\n          1.9105e-04,  1.2463e-04, -3.4984e-05, -2.5662e-04, -2.1692e-04,\n          8.3237e-05,  6.3652e-05,  3.7308e-05, -9.2389e-05, -7.4511e-05,\n          3.6397e-04, -2.2515e-04, -3.1978e-06,  2.0562e-04, -2.6355e-04,\n         -1.5869e-04, -8.0955e-05,  6.4648e-05, -3.1565e-05, -1.0968e-04,\n         -1.8047e-04, -7.1590e-07, -2.5983e-04, -1.9317e-04,  2.9540e-04,\n          5.5556e-06,  1.2793e-04,  4.5833e-04, -1.4352e-04],\n        [ 2.5615e-05,  8.9157e-05,  2.2728e-04,  7.8412e-05,  7.0072e-05,\n         -8.2225e-06,  1.8398e-04, -1.7557e-04, -4.9577e-05, -2.0181e-04,\n          2.2953e-04,  8.0289e-05, -1.0147e-04, -3.7006e-04, -1.3539e-04,\n         -4.8777e-05,  3.8684e-04, -2.8579e-04, -2.1285e-04, -9.5808e-05,\n          4.7896e-06,  2.6965e-04, -1.9441e-04, -2.2681e-04, -3.2811e-05,\n         -1.2871e-04,  9.1471e-06,  2.2848e-04,  3.6967e-04, -1.7585e-04,\n          1.4976e-04,  1.3320e-04,  7.2154e-05,  2.9730e-04,  3.5222e-05,\n         -1.4162e-04,  1.6107e-04,  8.2557e-06, -1.3342e-04, -1.0052e-04,\n          6.3770e-05, -1.0830e-04, -1.2055e-04, -1.2519e-04,  1.5170e-04,\n         -1.7898e-04,  3.7073e-05, -2.6808e-05,  3.5857e-05, -3.1661e-04,\n         -6.4222e-05,  2.1133e-04,  1.1096e-04, -1.0445e-04,  7.4577e-05,\n          1.0834e-04,  1.0833e-04, -2.6766e-04,  1.9389e-04, -2.9231e-05,\n          2.2751e-04, -3.1723e-05, -2.2703e-04, -1.7047e-04],\n        [ 2.2131e-04,  1.5030e-04, -2.9338e-04,  3.2146e-05,  1.5257e-04,\n          1.2240e-04, -6.0884e-05,  7.2492e-05, -2.1611e-04,  1.6755e-04,\n          2.6932e-04,  1.2221e-04,  1.3974e-04, -8.0242e-05,  2.1477e-05,\n          1.0362e-04,  3.1609e-05,  9.2508e-05,  2.4358e-04, -1.0684e-04,\n          1.7963e-04, -2.2174e-05,  1.7952e-04, -1.2427e-04, -2.9459e-05,\n          1.5590e-04, -1.0099e-04,  1.0157e-04,  8.9714e-05,  3.6606e-04,\n          5.9639e-05, -1.0294e-04, -2.4286e-04, -3.7281e-04,  5.3049e-05,\n         -1.1321e-04, -1.6968e-04,  7.8015e-05,  1.5457e-04,  3.0221e-04,\n         -1.5367e-04, -1.1320e-04,  1.3706e-04, -7.1839e-07, -7.6540e-05,\n         -1.9990e-04,  2.2998e-04,  6.8616e-05, -1.5733e-04,  3.3936e-04,\n          3.8677e-05,  1.3801e-04, -2.4857e-04,  2.7597e-04, -2.4808e-04,\n         -2.1684e-04, -1.0362e-04,  8.0394e-05, -1.7122e-04,  3.0142e-05,\n          4.5720e-05,  4.9990e-05, -3.2621e-05,  2.4670e-05],\n        [ 1.3311e-04,  5.8178e-05, -5.1962e-04,  1.4120e-05,  3.2843e-05,\n         -2.7239e-05, -1.2088e-04,  3.1911e-05, -1.3782e-05,  5.0989e-04,\n         -1.8269e-04, -9.1882e-05,  1.5265e-04, -4.3991e-05,  2.7312e-04,\n         -1.2336e-04, -3.9753e-04,  1.8099e-04,  7.5232e-05,  6.3770e-05,\n          1.4070e-04, -3.4586e-04,  1.6339e-04, -3.1401e-04,  1.0206e-05,\n          3.5524e-04, -1.3788e-04, -9.2575e-05, -2.2209e-04,  1.2867e-05,\n          5.5744e-05,  2.0472e-04, -2.4235e-05, -6.6481e-05,  3.4008e-05,\n          5.4392e-04, -3.0646e-04,  7.4548e-05, -1.0762e-05, -7.2474e-05,\n         -7.7712e-05,  1.5156e-04,  8.1056e-05, -1.6004e-04,  3.0268e-05,\n         -1.1995e-04,  2.4063e-04,  2.1434e-04, -6.2184e-05,  4.3012e-05,\n          1.1655e-04, -9.3624e-06, -1.4078e-04,  1.4023e-04, -2.5320e-04,\n         -9.9876e-05, -3.4920e-04,  2.1891e-04, -1.4790e-04,  6.0564e-05,\n         -8.3164e-05,  3.7777e-04,  2.7769e-05,  9.6797e-05],\n        [-1.3889e-04,  8.7483e-05,  2.5227e-05, -2.4658e-05,  6.1835e-05,\n          6.5679e-06,  2.4204e-04,  1.1057e-04, -1.6260e-04,  4.4136e-05,\n         -3.7906e-05,  4.0232e-05, -3.5899e-05,  1.0261e-04,  2.1938e-05,\n         -1.7540e-04,  2.1841e-05, -7.5219e-06, -7.9512e-06, -6.9269e-06,\n          9.2215e-05,  9.5702e-05,  1.0829e-04, -1.9034e-04, -1.8346e-04,\n         -1.1783e-04,  5.7415e-05,  1.0093e-04, -3.0520e-06,  9.6392e-05,\n         -7.3337e-05, -2.5851e-05, -4.9220e-05, -1.0821e-04,  1.9318e-04,\n         -9.9491e-05, -1.0293e-05, -1.5101e-05,  9.7646e-05,  1.8927e-04,\n         -1.4525e-04,  2.7554e-05,  9.7248e-05,  1.2790e-04,  9.7972e-05,\n          7.4912e-05,  5.8865e-05, -1.9588e-05,  9.7169e-06,  7.9183e-05,\n         -1.7993e-05, -2.5024e-05, -4.7563e-05, -1.5920e-04, -3.7866e-05,\n          1.2090e-04,  1.1338e-04,  1.0590e-04,  2.9252e-04, -2.3601e-04,\n          1.3579e-04, -1.2445e-04,  5.3432e-05,  1.4176e-04]])",
                    "exp_avg_sq":	"tensor([[2.4226e-07, 2.1528e-07, 7.0279e-07, 3.2522e-07, 2.7714e-07, 3.6044e-07,\n         1.5920e-07, 4.4014e-07, 1.5328e-07, 2.2891e-07, 1.9602e-07, 3.7271e-07,\n         4.0706e-07, 2.5904e-07, 2.6381e-07, 1.2388e-07, 1.9899e-07, 2.7961e-07,\n         7.7282e-07, 1.5696e-07, 8.7930e-07, 1.8360e-07, 3.4837e-07, 9.5991e-07,\n         4.5593e-07, 1.0536e-07, 2.2679e-07, 2.6029e-07, 6.6323e-07, 2.8539e-07,\n         2.6239e-07, 1.9149e-07, 3.5908e-07, 3.6524e-07, 1.3187e-07, 7.0096e-07,\n         1.9597e-07, 3.5794e-07, 5.0216e-07, 3.4533e-07, 1.1841e-07, 3.0632e-07,\n         2.6001e-07, 1.2382e-07, 1.5810e-07, 6.0994e-07, 3.4749e-07, 1.0816e-07,\n         3.9541e-07, 6.0503e-07, 1.8656e-07, 4.3381e-07, 2.8953e-07, 5.5029e-07,\n         3.3997e-07, 9.3743e-07, 2.0881e-07, 4.0699e-07, 1.1578e-06, 3.7208e-07,\n         9.1729e-08, 1.2207e-06, 7.7668e-07, 3.2722e-07],\n        [2.1719e-07, 1.5412e-07, 1.8773e-07, 2.5352e-07, 2.1524e-07, 8.0792e-08,\n         1.0531e-07, 2.0354e-07, 6.5811e-08, 1.3688e-07, 1.0248e-07, 2.4031e-07,\n         4.2887e-08, 1.2118e-07, 9.5370e-08, 6.0410e-08, 1.0613e-07, 1.0548e-07,\n         6.7721e-07, 1.0584e-07, 6.0243e-07, 1.1852e-07, 8.7138e-08, 5.8654e-07,\n         8.3372e-08, 7.1627e-08, 1.4621e-07, 1.1606e-07, 2.0171e-07, 1.3538e-07,\n         4.7584e-08, 1.4560e-07, 1.1354e-07, 6.0098e-08, 9.7320e-08, 4.5354e-07,\n         5.0494e-08, 1.0112e-07, 3.2642e-07, 1.0334e-07, 5.4571e-08, 1.0600e-07,\n         8.2660e-08, 6.2723e-08, 6.8201e-08, 5.3447e-07, 1.2680e-07, 8.1543e-08,\n         9.3254e-08, 4.6980e-07, 9.3702e-08, 2.3914e-07, 1.7230e-07, 1.4247e-07,\n         9.4739e-08, 1.5204e-07, 9.7103e-08, 8.3826e-08, 2.5148e-07, 2.1308e-07,\n         5.5302e-08, 1.1349e-06, 5.5190e-07, 1.8030e-07],\n        [1.2631e-07, 2.8260e-07, 9.7348e-07, 1.2649e-07, 1.8334e-07, 5.1725e-07,\n         1.7366e-07, 5.0222e-07, 2.2568e-07, 1.1277e-07, 4.1127e-07, 2.3299e-07,\n         7.8278e-07, 5.7044e-07, 6.0257e-07, 1.8915e-07, 1.9220e-07, 1.8675e-07,\n         6.5524e-07, 2.0086e-07, 1.7283e-07, 9.5809e-08, 7.0326e-07, 2.2425e-07,\n         1.1947e-06, 9.6808e-08, 2.8607e-07, 3.4264e-07, 1.1254e-06, 4.1275e-07,\n         7.8165e-07, 1.8565e-07, 7.8806e-07, 7.9221e-07, 7.1488e-08, 2.3916e-07,\n         1.8112e-07, 5.6872e-07, 6.4240e-07, 5.2174e-07, 6.3019e-08, 4.8683e-07,\n         6.0193e-07, 3.0365e-07, 1.5274e-07, 4.1043e-07, 1.6588e-07, 3.0721e-07,\n         7.1450e-07, 5.0724e-07, 1.2225e-07, 4.5499e-07, 1.5035e-07, 8.4287e-07,\n         4.2995e-07, 1.5565e-06, 2.1678e-07, 1.2427e-06, 1.9184e-06, 3.4141e-07,\n         1.0184e-07, 4.4327e-07, 2.4151e-07, 5.7117e-07],\n        [1.6776e-07, 1.8424e-07, 2.6439e-07, 1.9460e-07, 1.7210e-07, 1.2322e-07,\n         1.2408e-07, 2.2133e-07, 8.3636e-08, 1.5319e-07, 1.3584e-07, 1.9103e-07,\n         1.9010e-07, 1.5280e-07, 1.5216e-07, 6.1915e-08, 9.4703e-08, 1.1505e-07,\n         5.1750e-07, 9.2086e-08, 5.3858e-07, 1.2679e-07, 2.1430e-07, 5.9558e-07,\n         1.7979e-07, 1.0876e-07, 1.2413e-07, 1.0368e-07, 1.7595e-07, 1.3557e-07,\n         1.2533e-07, 1.3320e-07, 1.5384e-07, 1.7752e-07, 6.5863e-08, 5.0037e-07,\n         1.1158e-07, 1.6071e-07, 2.7895e-07, 1.5858e-07, 4.9718e-08, 2.0969e-07,\n         8.3352e-08, 7.8365e-08, 8.5000e-08, 3.9581e-07, 2.2579e-07, 9.8259e-08,\n         2.1864e-07, 3.6078e-07, 1.0853e-07, 2.7010e-07, 1.6715e-07, 2.9505e-07,\n         1.2752e-07, 3.6262e-07, 1.5322e-07, 1.8397e-07, 4.2014e-07, 2.8442e-07,\n         7.1992e-08, 8.1777e-07, 5.2229e-07, 1.6333e-07],\n        [3.1242e-07, 4.7283e-07, 1.5580e-06, 1.9734e-07, 3.7427e-07, 5.7990e-07,\n         3.7236e-07, 6.9948e-07, 2.9408e-07, 2.5817e-07, 6.7324e-07, 4.0877e-07,\n         1.1720e-06, 7.6585e-07, 7.8267e-07, 3.5991e-07, 3.7013e-07, 4.4790e-07,\n         1.2001e-06, 2.8908e-07, 4.5861e-07, 2.4706e-07, 1.0909e-06, 5.6252e-07,\n         1.4267e-06, 2.2114e-07, 3.6299e-07, 6.1354e-07, 1.3113e-06, 7.4386e-07,\n         1.0116e-06, 4.1614e-07, 1.1003e-06, 1.1951e-06, 1.9793e-07, 6.1816e-07,\n         2.9522e-07, 8.1953e-07, 1.0552e-06, 9.4913e-07, 1.2896e-07, 9.6779e-07,\n         6.6939e-07, 5.5638e-07, 3.1745e-07, 9.0700e-07, 4.1501e-07, 6.1809e-07,\n         1.1767e-06, 1.0944e-06, 1.5336e-07, 1.1147e-06, 3.4448e-07, 1.2312e-06,\n         6.4280e-07, 1.7454e-06, 4.5237e-07, 1.3320e-06, 2.1152e-06, 8.8301e-07,\n         1.9419e-07, 8.7718e-07, 3.6270e-07, 6.4677e-07],\n        [1.5987e-07, 2.4054e-07, 7.5372e-07, 2.0442e-07, 2.1563e-07, 3.5368e-07,\n         1.5437e-07, 3.6837e-07, 2.3047e-07, 2.3658e-07, 4.1601e-07, 2.8479e-07,\n         5.2737e-07, 3.9732e-07, 4.7074e-07, 1.6710e-07, 2.0857e-07, 2.9379e-07,\n         6.0754e-07, 1.6153e-07, 4.1027e-07, 1.2853e-07, 4.8549e-07, 3.9946e-07,\n         7.2861e-07, 1.4253e-07, 1.9363e-07, 2.9002e-07, 7.4407e-07, 4.7805e-07,\n         4.5416e-07, 1.8069e-07, 5.6593e-07, 6.0735e-07, 1.1984e-07, 3.1077e-07,\n         1.8428e-07, 4.0627e-07, 4.9783e-07, 4.4279e-07, 1.4698e-07, 3.5514e-07,\n         3.9644e-07, 2.0576e-07, 1.9420e-07, 5.0127e-07, 2.2870e-07, 2.2377e-07,\n         5.3651e-07, 6.0811e-07, 1.0961e-07, 4.7035e-07, 3.1351e-07, 6.0786e-07,\n         3.8627e-07, 9.7254e-07, 1.9319e-07, 7.1379e-07, 1.1578e-06, 3.4982e-07,\n         9.5833e-08, 5.8869e-07, 2.5887e-07, 3.6595e-07],\n        [3.8637e-07, 3.2308e-07, 6.9120e-07, 3.0572e-07, 3.7265e-07, 2.7937e-07,\n         3.2372e-07, 5.3701e-07, 2.4929e-07, 3.5605e-07, 3.1726e-07, 3.0106e-07,\n         4.2532e-07, 4.5731e-07, 4.6309e-07, 2.8420e-07, 2.6068e-07, 2.3848e-07,\n         1.0481e-06, 2.4192e-07, 6.2291e-07, 2.2393e-07, 6.2873e-07, 7.2301e-07,\n         6.1503e-07, 3.0129e-07, 4.2415e-07, 3.7519e-07, 4.8966e-07, 4.6848e-07,\n         4.8214e-07, 3.8835e-07, 5.3071e-07, 5.7532e-07, 2.0539e-07, 8.1826e-07,\n         3.2875e-07, 3.6653e-07, 6.8427e-07, 5.3803e-07, 1.6505e-07, 4.9706e-07,\n         3.3350e-07, 3.0244e-07, 2.8789e-07, 7.4151e-07, 3.9923e-07, 2.7628e-07,\n         5.7849e-07, 7.7232e-07, 2.9707e-07, 6.3958e-07, 3.8776e-07, 4.7782e-07,\n         3.2341e-07, 6.2322e-07, 3.9697e-07, 6.5199e-07, 7.9627e-07, 5.6087e-07,\n         2.2316e-07, 1.2325e-06, 8.1215e-07, 5.1647e-07],\n        [2.0248e-07, 3.5767e-07, 2.0226e-06, 3.0760e-07, 1.5033e-07, 8.7041e-07,\n         2.7397e-07, 3.5721e-07, 3.1831e-07, 3.7496e-07, 4.0154e-07, 5.8724e-07,\n         9.1358e-07, 5.7737e-07, 6.8121e-07, 1.5175e-07, 6.2159e-07, 8.0599e-07,\n         3.2348e-07, 4.8666e-07, 1.0366e-06, 3.2550e-07, 5.2315e-07, 1.1996e-06,\n         1.0952e-06, 2.5197e-07, 3.0364e-07, 2.1419e-07, 1.8438e-06, 2.0533e-07,\n         5.0859e-07, 3.4284e-07, 3.9785e-07, 2.6186e-07, 2.3104e-07, 5.0931e-07,\n         1.6366e-07, 9.9692e-07, 3.0413e-07, 2.4717e-07, 2.4953e-07, 4.5233e-07,\n         6.9485e-07, 1.6187e-07, 2.6096e-07, 3.6449e-07, 6.0967e-07, 2.3131e-07,\n         4.6630e-07, 2.9627e-07, 2.3825e-07, 5.0841e-07, 5.4706e-07, 1.6617e-06,\n         7.6469e-07, 2.3560e-06, 3.9903e-07, 9.7345e-07, 3.0383e-06, 5.4851e-07,\n         1.5171e-07, 6.7324e-07, 4.7715e-07, 4.5544e-07]])",
                    "step":	45952
                },
                "139862174597264":	{
                    "exp_avg":	"tensor([[-6.5641e-05,  6.4912e-06,  1.4924e-05,  ..., -2.8049e-06,\n         -1.6843e-05,  6.0172e-05],\n        [ 1.5409e-05,  1.9753e-06, -1.3294e-05,  ...,  6.5419e-05,\n         -2.7918e-05, -1.4399e-05],\n        [ 4.3431e-05, -2.2252e-05, -1.9050e-05,  ..., -8.0857e-05,\n         -6.7814e-05, -5.0876e-05],\n        ...,\n        [ 7.1548e-05, -2.7068e-05, -9.9437e-05,  ...,  1.4213e-04,\n          8.5309e-07,  1.1937e-04],\n        [-3.3065e-06, -5.8512e-05, -2.7856e-05,  ..., -5.8567e-05,\n         -1.0123e-04, -4.3736e-05],\n        [ 4.5277e-05, -7.3584e-05, -8.7921e-05,  ..., -5.9920e-05,\n          9.8206e-06, -6.1757e-05]])",
                    "exp_avg_sq":	"tensor([[5.8228e-08, 2.1541e-07, 5.7479e-08,  ..., 1.6973e-07, 1.1381e-07,\n         1.4345e-07],\n        [3.5043e-08, 7.7833e-08, 2.0110e-08,  ..., 4.1856e-08, 3.2667e-08,\n         4.5889e-08],\n        [3.0008e-08, 5.4177e-08, 1.5588e-08,  ..., 3.5597e-08, 2.2714e-08,\n         3.2662e-08],\n        ...,\n        [2.1263e-08, 7.6752e-08, 2.4798e-08,  ..., 1.2544e-07, 5.8650e-08,\n         8.7937e-08],\n        [3.4565e-08, 7.5339e-08, 2.5401e-08,  ..., 4.6888e-08, 3.0335e-08,\n         4.6274e-08],\n        [4.1076e-08, 8.7889e-08, 2.5210e-08,  ..., 5.5582e-08, 3.3055e-08,\n         4.9739e-08]])",
                    "step":	45952
                },
                "139862174597696":	{
                    "exp_avg":	"tensor([ 7.1827e-05,  8.2610e-05, -1.0295e-04,  1.2471e-04, -2.6031e-04,\n         1.4077e-04, -2.0151e-04,  1.4581e-04,  1.2282e-05,  2.1261e-06,\n        -5.3078e-05,  9.1448e-06, -6.6603e-05, -1.8753e-04,  1.2057e-04,\n         4.8595e-05,  4.8813e-05, -1.4783e-04, -2.8624e-04, -8.6564e-05,\n         9.7631e-05,  2.5589e-04, -1.9423e-04, -9.2191e-06,  1.0687e-04,\n        -3.8256e-05, -4.0521e-05, -2.4607e-04,  7.5091e-05, -1.5189e-04,\n         1.3902e-04, -9.4361e-05,  2.4037e-04,  3.2794e-04,  2.7947e-05,\n        -3.5653e-05,  9.2412e-05,  1.0352e-04,  4.0734e-05, -2.4319e-04,\n         5.9434e-05, -1.9358e-04, -8.4577e-05,  3.3911e-05,  3.7995e-05,\n        -1.3837e-04,  2.4114e-04,  4.7193e-05,  7.2259e-05, -3.3910e-04,\n         1.7006e-04, -1.0476e-04, -4.9880e-05,  1.6882e-04, -7.8904e-05,\n        -4.2094e-05, -4.2170e-05, -5.3509e-05,  9.1091e-05,  3.7470e-04,\n        -5.5965e-05,  3.9977e-04, -2.5187e-04, -1.4689e-04])",
                    "exp_avg_sq":	"tensor([6.6194e-06, 2.0532e-06, 2.0532e-06, 3.3611e-06, 3.5904e-06, 1.3761e-06,\n        3.2707e-06, 3.5792e-06, 4.2680e-06, 4.2898e-06, 2.0760e-06, 5.0575e-06,\n        2.6241e-06, 5.7930e-06, 5.3969e-07, 2.3331e-06, 7.7041e-06, 3.3772e-06,\n        5.5671e-06, 4.1441e-06, 4.5790e-06, 6.7638e-06, 2.4688e-06, 3.9583e-06,\n        2.9170e-06, 8.6609e-06, 4.0290e-06, 1.5210e-06, 1.4729e-06, 5.4469e-06,\n        3.7786e-06, 6.2337e-06, 2.9292e-06, 1.0506e-05, 1.1345e-05, 3.5403e-06,\n        5.3073e-06, 8.7964e-07, 6.8654e-06, 5.7665e-06, 7.8792e-06, 1.7745e-06,\n        2.8765e-06, 5.8153e-06, 2.3035e-06, 2.9211e-06, 2.5200e-06, 4.1537e-06,\n        3.8411e-06, 1.4564e-05, 2.0940e-06, 9.2412e-07, 4.8348e-06, 2.3877e-06,\n        2.0162e-06, 8.7200e-07, 4.6759e-06, 4.3046e-06, 9.8149e-07, 3.8306e-06,\n        3.9382e-06, 3.6324e-06, 1.8773e-06, 2.6673e-06])",
                    "step":	45952
                },
                "139862174598704":	{
                    "exp_avg":	"tensor([ 6.4843e-04, -1.2970e-03, -6.6649e-04,  1.4760e-05, -2.1698e-04,\n        -4.7283e-04, -2.7452e-04, -5.7138e-04,  2.7302e-04, -3.9045e-04,\n         1.1680e-03,  3.2470e-04,  6.0637e-06, -7.5296e-05, -5.1980e-04,\n        -8.7397e-04, -1.3276e-04,  1.3585e-05,  7.5333e-04,  2.8564e-04,\n         9.3536e-04, -3.2055e-04,  2.4504e-04, -7.3323e-04, -1.3333e-03,\n        -5.0499e-04,  4.5894e-05, -9.5505e-04, -3.2861e-04,  7.2580e-04,\n         3.1271e-04,  4.6520e-04,  1.0706e-04, -2.3298e-04,  9.6230e-05,\n         3.2949e-04, -6.0113e-05, -2.5988e-04,  8.5391e-04, -7.5827e-04,\n         1.3037e-04,  8.5349e-04,  3.8996e-05, -1.6003e-04, -1.6810e-04,\n        -1.0807e-05,  2.7139e-04,  6.1506e-05, -9.0485e-04, -6.4378e-04,\n         2.1294e-04,  7.0965e-04, -1.5014e-04,  7.4741e-04,  7.3597e-04,\n        -9.2863e-04, -1.1729e-03, -5.5246e-05, -2.5602e-04,  4.7547e-04,\n        -6.9950e-04,  3.3237e-04, -3.1735e-04,  2.2497e-04])",
                    "exp_avg_sq":	"tensor([1.2237e-04, 3.8286e-04, 1.9375e-04, 2.4375e-05, 3.5369e-05, 8.8135e-05,\n        3.9382e-05, 1.3269e-04, 3.2996e-05, 6.6919e-05, 4.2492e-04, 2.6061e-05,\n        8.9146e-06, 2.9640e-05, 6.6265e-05, 2.8078e-04, 4.3063e-05, 6.9202e-05,\n        2.1139e-04, 4.1023e-06, 2.9431e-04, 4.9556e-06, 6.9946e-05, 2.1554e-04,\n        1.5496e-03, 8.3705e-05, 6.0519e-06, 3.3534e-04, 7.5928e-05, 5.0518e-05,\n        4.2332e-04, 7.0844e-05, 1.1663e-05, 1.7264e-05, 5.3163e-05, 4.1143e-05,\n        3.7474e-05, 1.6737e-04, 1.7157e-04, 2.5024e-04, 7.6784e-05, 1.6635e-04,\n        9.4905e-05, 1.1512e-04, 4.4936e-05, 8.9471e-06, 8.5999e-05, 1.6211e-04,\n        1.8302e-04, 1.3283e-04, 8.3351e-05, 5.2478e-05, 2.6760e-04, 5.5236e-05,\n        4.6990e-05, 3.0316e-04, 5.2380e-04, 4.3172e-05, 5.6130e-05, 3.3693e-04,\n        1.7228e-04, 2.1590e-04, 4.8158e-05, 3.7095e-05])",
                    "step":	45952
                },
                "139862174599568":	{
                    "exp_avg":	"tensor([[ 2.7673e-06, -7.5133e-05,  4.7290e-04,  ..., -5.9955e-06,\n         -2.7976e-05, -1.6412e-05],\n        [-3.3782e-04,  1.2493e-04, -1.2765e-03,  ..., -2.8174e-05,\n         -1.0285e-05,  5.2660e-05],\n        [-8.8895e-05,  1.7436e-04, -4.9513e-04,  ..., -2.0285e-05,\n          1.5194e-04,  5.9744e-05],\n        ...,\n        [ 9.3197e-05,  7.6761e-05,  2.5390e-04,  ..., -2.9258e-05,\n          9.3026e-05,  4.1262e-06],\n        [-4.0861e-05, -5.7934e-05, -2.0472e-04,  ...,  7.1393e-06,\n         -9.1001e-06,  6.5407e-05],\n        [ 1.1325e-04,  5.8234e-05,  1.6692e-04,  ..., -1.2767e-05,\n          1.0750e-04, -8.3507e-05]])",
                    "exp_avg_sq":	"tensor([[3.0889e-06, 6.3289e-06, 9.4627e-05,  ..., 7.3420e-09, 5.0197e-08,\n         2.5246e-08],\n        [9.7447e-06, 1.8880e-05, 2.9783e-04,  ..., 2.0746e-08, 1.0172e-07,\n         6.0912e-08],\n        [4.7492e-06, 7.2494e-06, 1.6093e-04,  ..., 9.4036e-09, 4.2740e-08,\n         5.6421e-08],\n        ...,\n        [5.2255e-06, 9.4216e-06, 1.7274e-04,  ..., 1.0797e-08, 3.3220e-08,\n         3.2718e-08],\n        [1.1921e-06, 2.1892e-06, 3.8228e-05,  ..., 2.3657e-09, 8.5976e-09,\n         7.0140e-09],\n        [9.4500e-07, 1.4439e-06, 3.1058e-05,  ..., 2.3267e-09, 1.3125e-08,\n         1.1111e-08]])",
                    "step":	45952
                },
                "139862174599712":	{
                    "exp_avg":	"tensor([-4.7456e-05, -1.9012e-04,  1.2744e-06, -1.8951e-05,  3.8660e-05,\n        -1.9032e-04, -1.4801e-04,  2.4594e-04])",
                    "exp_avg_sq":	"tensor([4.4429e-06, 1.9372e-06, 3.5792e-06, 2.0409e-06, 3.7696e-06, 2.5980e-06,\n        2.3947e-06, 8.0748e-06])",
                    "step":	45952
                }
            }
        },
        "vf_optimizer":	{
            "param_groups":	[
                {
                    "amsgrad":	false,
                    "betas":	[
                        0.9,
                        0.999
                    ],
                    "eps":	1e-08,
                    "lr":	0.0001,
                    "params":	[
                        139862174599640,
                        139862174599496,
                        139862174599424,
                        139862168840232,
                        139862168840448,
                        139862168841096
                    ],
                    "weight_decay":	0
                }
            ],
            "state":	{
                "139862168840232":	{
                    "exp_avg":	"tensor([-0.0788,  0.0362,  0.0782, -0.0450, -0.0553,  0.0404, -0.0243, -0.0158,\n        -0.0114,  0.0086,  0.0865, -0.0429,  0.0243,  0.0581, -0.0377,  0.0198,\n        -0.0908, -0.0797,  0.0904, -0.0141,  0.0257,  0.0560, -0.1029,  0.0053,\n         0.1293,  0.0730, -0.0602, -0.0467,  0.0439, -0.0383, -0.0227, -0.0367,\n        -0.0107, -0.0132,  0.0506,  0.0145, -0.0231, -0.0468, -0.0567,  0.1027,\n         0.0285,  0.0343,  0.0969, -0.0206, -0.0213,  0.0132,  0.1407, -0.0368,\n         0.0294, -0.0297,  0.0032, -0.0984, -0.0461, -0.0045,  0.0489, -0.0379,\n         0.0367,  0.0190, -0.0295, -0.0039,  0.0146, -0.0011, -0.0016, -0.1382])",
                    "exp_avg_sq":	"tensor([0.0259, 0.0160, 0.0170, 0.0566, 0.0113, 0.0293, 0.0365, 0.0681, 0.0407,\n        0.0784, 0.0425, 0.0593, 0.0345, 0.0433, 0.0201, 0.0249, 0.0486, 0.0751,\n        0.0324, 0.0726, 0.0294, 0.0590, 0.0476, 0.0323, 0.0162, 0.0135, 0.0812,\n        0.0129, 0.0577, 0.0217, 0.0356, 0.0269, 0.0330, 0.0316, 0.0925, 0.0589,\n        0.0320, 0.0192, 0.0509, 0.0264, 0.0687, 0.0710, 0.0635, 0.0589, 0.0043,\n        0.0211, 0.0641, 0.0738, 0.0060, 0.0273, 0.0232, 0.0375, 0.0457, 0.0201,\n        0.0277, 0.0221, 0.1141, 0.0303, 0.0149, 0.0045, 0.0743, 0.0365, 0.0243,\n        0.1034])",
                    "step":	45952
                },
                "139862168840448":	{
                    "exp_avg":	"tensor([[ 0.0035,  0.1126, -0.0552, -0.0238,  0.0839, -0.0472, -0.0164,  0.0025,\n          0.0628, -0.0041, -0.1325, -0.1932,  0.0082,  0.0144, -0.0164, -0.0248,\n         -0.0296,  0.0220, -0.0047,  0.0541, -0.0073, -0.0109, -0.0441,  0.0210,\n         -0.0244, -0.0367, -0.0386,  0.1178, -0.0446, -0.0911, -0.0586,  0.0029,\n         -0.0259, -0.0307,  0.0301, -0.0010, -0.0116, -0.0030,  0.0594, -0.0230,\n          0.0056,  0.0514, -0.0493,  0.1662,  0.0699, -0.0127,  0.0375, -0.0450,\n          0.0446, -0.0308,  0.0165,  0.0202,  0.0226,  0.0822,  0.0238,  0.0286,\n          0.0511,  0.0032, -0.0102,  0.0622,  0.0342, -0.0342,  0.1043,  0.0140]])",
                    "exp_avg_sq":	"tensor([[0.1212, 0.1550, 0.4204, 0.1383, 0.2554, 0.1897, 0.2003, 0.1290, 0.3000,\n         0.1657, 0.1677, 0.1386, 0.2585, 0.3003, 0.1268, 0.1196, 0.2813, 0.2020,\n         0.2468, 0.1555, 0.3229, 0.2181, 0.2064, 0.2632, 0.4293, 0.4126, 0.1406,\n         0.4020, 0.2032, 0.3585, 0.3345, 0.2602, 0.2571, 0.1028, 0.1653, 0.1416,\n         0.3191, 0.2541, 0.1169, 0.1133, 0.1252, 0.2408, 0.1787, 0.1422, 0.2586,\n         0.1263, 0.2122, 0.1375, 0.2597, 0.2128, 0.3343, 0.2332, 0.2426, 0.3563,\n         0.1117, 0.1194, 0.1082, 0.1315, 0.2401, 0.2605, 0.2729, 0.2658, 0.3694,\n         0.1844]])",
                    "step":	45952
                },
                "139862168841096":	{
                    "exp_avg":	"tensor([0.0604])",
                    "exp_avg_sq":	"tensor([0.2597])",
                    "step":	45952
                },
                "139862174599424":	{
                    "exp_avg":	"tensor([[ 0.0153, -0.0108, -0.0640,  ...,  0.0293, -0.0453,  0.0051],\n        [ 0.0100, -0.0087,  0.0279,  ..., -0.0096,  0.0257,  0.0077],\n        [-0.0521, -0.0032,  0.0693,  ..., -0.0264,  0.0021, -0.0519],\n        ...,\n        [-0.0080, -0.0150, -0.0142,  ..., -0.0059,  0.0109, -0.0221],\n        [ 0.0134, -0.0350,  0.0047,  ...,  0.0016, -0.0023,  0.0186],\n        [ 0.0050,  0.0351, -0.0943,  ...,  0.0358, -0.0711,  0.0307]])",
                    "exp_avg_sq":	"tensor([[0.0025, 0.0026, 0.0137,  ..., 0.0033, 0.0039, 0.0043],\n        [0.0005, 0.0018, 0.0086,  ..., 0.0013, 0.0018, 0.0018],\n        [0.0009, 0.0041, 0.0098,  ..., 0.0011, 0.0023, 0.0020],\n        ...,\n        [0.0010, 0.0011, 0.0213,  ..., 0.0010, 0.0037, 0.0058],\n        [0.0017, 0.0023, 0.0145,  ..., 0.0010, 0.0032, 0.0026],\n        [0.0056, 0.0043, 0.0600,  ..., 0.0109, 0.0092, 0.0066]])",
                    "step":	45952
                },
                "139862174599496":	{
                    "exp_avg":	"tensor([-0.0251, -0.1025, -0.0896,  0.1327, -0.0248, -0.0786,  0.0127, -0.0455,\n        -0.0128, -0.0762,  0.0336,  0.0946, -0.0680, -0.0419,  0.0777, -0.0641,\n         0.0940,  0.0654,  0.3510, -0.1280,  0.1243, -0.0300,  0.0542, -0.0720,\n        -0.1197,  0.2561, -0.1261,  0.0481,  0.0470, -0.1953, -0.0344, -0.0179,\n        -0.0822,  0.1456, -0.0684,  0.0118, -0.0223, -0.0170, -0.0096, -0.0152,\n         0.0965,  0.0103,  0.0679, -0.1368,  0.0224, -0.0680, -0.1971, -0.0109,\n        -0.0099,  0.0027,  0.0141, -0.0116,  0.0115, -0.1363, -0.0770, -0.0963,\n         0.0161,  0.1354, -0.1873, -0.0872, -0.0645,  0.1842, -0.0670, -0.0028])",
                    "exp_avg_sq":	"tensor([ 6.2163,  3.6716,  0.3039,  4.6073,  0.7436,  6.8759,  3.3709,  1.7320,\n         2.0528,  2.9896,  2.4336,  6.1061,  2.1998,  3.9427,  3.4747,  2.8320,\n         0.8210,  3.2464,  3.3002,  2.6228,  0.3278,  1.4803,  2.4456,  2.9761,\n         1.6792,  2.0751, 11.0978,  0.4963,  1.5853,  1.8398,  2.4545,  4.6487,\n         7.8655,  1.7691,  3.7694,  3.3937,  1.6436,  2.2331,  4.1841,  3.3107,\n         2.4550,  2.5291,  2.9367, 12.8165,  1.6084,  7.5311,  5.9467,  0.8633,\n         4.4050,  3.8240,  3.2529,  0.3755,  3.5448,  3.4579,  8.0012,  1.2250,\n         2.4471,  1.2975,  2.2526,  2.4911,  2.9485,  2.0097,  1.4995,  3.6808])",
                    "step":	45952
                },
                "139862174599640":	{
                    "exp_avg":	"tensor([[ 1.0901e-01,  1.2451e-01, -1.9708e-02,  ...,  6.5947e-04,\n         -4.0435e-03,  1.0310e-02],\n        [-1.7641e-01,  3.8780e-01, -1.2751e-01,  ..., -4.5110e-03,\n         -1.5860e-03,  5.3081e-03],\n        [-1.2899e-02, -4.7898e-02, -7.9342e-02,  ...,  2.1702e-03,\n         -1.1250e-03,  2.9303e-04],\n        ...,\n        [ 1.6764e-01,  6.2358e-02,  1.7795e-01,  ..., -1.1610e-03,\n          1.0255e-03,  5.5548e-03],\n        [ 3.7282e-02, -1.1330e-01, -6.4035e-02,  ...,  2.4425e-03,\n         -1.5831e-03, -1.2975e-04],\n        [-1.1236e-01, -2.2665e-01, -2.8127e-02,  ..., -1.1923e-03,\n         -1.8346e-03, -8.5953e-03]])",
                    "exp_avg_sq":	"tensor([[1.6673e-01, 3.8867e-01, 4.7621e+00,  ..., 5.2248e-04, 7.3014e-04,\n         6.2709e-04],\n        [1.1173e-01, 3.8957e-01, 2.7223e+00,  ..., 3.7611e-04, 1.4327e-04,\n         1.0584e-04],\n        [1.0320e-02, 1.9718e-02, 2.4544e-01,  ..., 2.2160e-05, 1.4702e-05,\n         9.7886e-06],\n        ...,\n        [5.8246e-02, 1.4742e-01, 1.5695e+00,  ..., 1.8061e-04, 3.0593e-04,\n         2.7428e-04],\n        [4.1121e-02, 1.0154e-01, 1.1386e+00,  ..., 1.3170e-04, 9.6961e-05,\n         7.1475e-05],\n        [1.0177e-01, 2.3648e-01, 2.9601e+00,  ..., 3.0088e-04, 6.1239e-04,\n         5.7035e-04]])",
                    "step":	45952
                }
            }
        }
    },
    "clip_ratio":	0.2,
    "ent_coef":	0.0,
    "env_fn":	"<function main.<locals>.<lambda> at 0x7f9da19d4d90>",
    "epochs":	625,
    "exp_name":	"t:11_name:composuite_robot:IIWA_task:Shelf_object:Box_obstacle:ObjectWall",
    "gamma":	0.99,
    "lam":	0.97,
    "log_per_proc":	false,
    "logger":	{
        "<spinup.utils.logx.EpochLogger object at 0x7f9da19c15f8>":	{
            "epoch_dict":	{},
            "exp_name":	"t:11_name:composuite_robot:IIWA_task:Shelf_object:Box_obstacle:ObjectWall",
            "first_row":	true,
            "log_current_row":	{},
            "log_headers":	[],
            "output_dir":	"spinningup_training/collas_rebuttal_experiments/single_task/s0_ctd/t:11_name:composuite_robot:IIWA_task:Shelf_object:Box_obstacle:ObjectWall",
            "output_file":	{
                "<_io.TextIOWrapper name='spinningup_training/collas_rebuttal_experiments/single_task/s0_ctd/t:11_name:composuite_robot:IIWA_task:Shelf_object:Box_obstacle:ObjectWall/progress.txt' mode='w' encoding='UTF-8'>":	{
                    "mode":	"w"
                }
            }
        }
    },
    "logger_kwargs":	{
        "exp_name":	"t:11_name:composuite_robot:IIWA_task:Shelf_object:Box_obstacle:ObjectWall",
        "output_dir":	"spinningup_training/collas_rebuttal_experiments/single_task/s0_ctd/t:11_name:composuite_robot:IIWA_task:Shelf_object:Box_obstacle:ObjectWall"
    },
    "max_ep_len":	500,
    "pi_lr":	0.0001,
    "save_freq":	1,
    "seed":	0,
    "steps_per_epoch":	16000,
    "target_kl":	0.02,
    "train_pi_iters":	128,
    "train_v_iters":	128,
    "vf_lr":	0.0001
}